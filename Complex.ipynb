{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vk_api\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"cinemas.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание таблицы брендов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute('''CREATE TABLE brand(\n",
    "                    id integer PRIMARY KEY,\n",
    "                    name text NOT NULL)''')\n",
    "except sqlite3.OperationalError:\n",
    "    print('Таблица уже создана!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"insert into brand values (1, 'КАРО')\")\n",
    "    conn.commit()\n",
    "except sqlite3.IntegrityError:\n",
    "    print('Каро уже добавлен!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть1. Создание таблицы кинозалов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"\"\"CREATE TABLE cinema_halls(\n",
    "                id integer PRIMARY KEY,\n",
    "                brand_id integer Not NULL,\n",
    "                site_id integer Not NULL,\n",
    "                name text NOT NULL,\n",
    "                address text NOT NULL,\n",
    "                metro text NULL,\n",
    "                phone text NOT NULL,\n",
    "                FOREIGN KEY (brand_id) REFERENCES brand(id)\n",
    "                )\"\"\")\n",
    "except sqlite3.OperationalError:\n",
    "    print('Таблица уже создана!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all(string):\n",
    "    pattern = re.compile(r'[А-Яа-яёЁ0-9 ]+')\n",
    "    return pattern.findall(string)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_theaters_KARO(theatres):\n",
    "    dicti = {}\n",
    "    metro_class = 'cinemalist__cinema-item__metro__station-list__station-item'\n",
    "    for theater in theatres:\n",
    "        dicti[theater.findAll('h4')[0].text.strip()] = {\n",
    "            'metro': [remove_all(i.text) for i in theater.findAll('li', class_=metro_class)], \n",
    "            'address': theater.findAll('p')[0].text.split('+')[0].strip(),\n",
    "            'phone': '+' + theater.findAll('p')[0].text.split('+')[-1],\n",
    "            'data-id': theater['data-id']\n",
    "        }\n",
    "    return dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://karofilm.ru\"\n",
    "url_theaters = url + \"/theatres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url_theaters)\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    theatres = soup.findAll('li', class_='cinemalist__cinema-item')\n",
    "    karo_theatres = find_all_theaters_KARO(theatres)\n",
    "else:\n",
    "    print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем базу данных кинотеаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, theater in enumerate(karo_theatres):\n",
    "    adress = karo_theatres[theater]['address']\n",
    "    metro = \", \".join(karo_theatres[theater]['metro'])\n",
    "    phone = karo_theatres[theater]['phone']\n",
    "    site_id = karo_theatres[theater]['data-id']\n",
    "    cursor.execute(f\"insert into cinema_halls values ('{i + 1}', {1}, '{site_id}', '{theater}', '{adress}', '{metro}', '{phone}')\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть2. Создание таблицы фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"\"\"CREATE TABLE cinemas(\n",
    "                id integer PRIMARY KEY,\n",
    "                site_id integer NOT NULL,\n",
    "                name text NOT NULL,\n",
    "                duration integer NOT NULL,\n",
    "                language text NOT NULL,\n",
    "                genres text NOT NULL\n",
    "                )\"\"\")\n",
    "except sqlite3.OperationalError:\n",
    "    print('Таблица уже создана!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(cinema_href):\n",
    "    url_cinema = url + \"/film/\" + cinema_href\n",
    "    r = requests.get(url_cinema)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    film_age = soup.findAll('span', class_='fp_header-age')[0].text\n",
    "    return film_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_cinemas_KARO(cinemas):\n",
    "    cinemas_dicti = {}\n",
    "    for cinema in cinemas: \n",
    "        cinema_title = cinema.findAll('h3', class_='afisha-title')[0].text.strip()\n",
    "        try:\n",
    "            cinema_genres = \", \".join(cinema.findAll('p',class_='afisha-genre')[0].text.split(' / '))\n",
    "        except IndexError:\n",
    "            cinema_genres='undefined' \n",
    "        if cinema['data-cinemas']:\n",
    "            cinema_hallss = cinema['data-cinemas'].split(',')\n",
    "        else:\n",
    "            cinema_hallss = []\n",
    "        cinema_href = cinema['data-id']\n",
    "        cinema_duration = cinema.findAll('span', class_=\"afisha-duration-time\")[0].text\n",
    "        cinema_age = age(cinema_href)\n",
    "        cinema_language='undefined'\n",
    "        cinemas_dicti[cinema_title] = {'age': cinema_age, 'duration': cinema_duration, 'language': cinema_language, 'genres': cinema_genres, 'halls': cinema_hallss,'href': cinema_href}\n",
    "    return cinemas_dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "if r.status_code == 200:\n",
    "    soup2 = BeautifulSoup(r.text, \"html.parser\")\n",
    "    cinemas = soup2.findAll('div', class_='afisha-item')\n",
    "    karo_cinemas = find_all_cinemas_KARO(cinemas)\n",
    "else:\n",
    "    print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cinema in enumerate(karo_cinemas):\n",
    "    duration = karo_cinemas[cinema]['duration']\n",
    "    language = karo_cinemas[cinema]['language']\n",
    "    genres = karo_cinemas[cinema]['genres']\n",
    "    href = karo_cinemas[cinema]['href']\n",
    "    cursor.execute(f\"insert into cinemas values ('{i + 1}', '{href}', '{cinema}', '{duration}', '{language}', '{genres}')\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Создание таблицы сеансов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"\"\"CREATE TABLE sessions(\n",
    "                id integer PRIMARY KEY,\n",
    "                cinema_id integer Not NULL,\n",
    "                hall_id integer Not NULL,\n",
    "                date date NOT NULL,\n",
    "                form text NOT NULL,\n",
    "                time time NOT NULL,\n",
    "                price integer NOT NULL,\n",
    "                FOREIGN KEY (cinema_id) REFERENCES cinemas(id),\n",
    "                FOREIGN KEY (hall_id) REFERENCES cinema_halls(id)\n",
    "                )\"\"\")\n",
    "except sqlite3.OperationalError:\n",
    "    print('Таблица уже создана!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(name, base):\n",
    "    list_base = cursor.execute(f'select * from \"{base}\"').fetchall()\n",
    "    if base == \"cinemas\":\n",
    "        k = 2\n",
    "    elif base == \"cinema_halls\":\n",
    "        k = 3\n",
    "    for element in list_base:\n",
    "        if (name == element[k]) or (name in element[k]) or (element[k] in name):\n",
    "            return element[0]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = \"cinema-page-item__schedule__row__board-row__left\"\n",
    "right = \"cinema-page-item__schedule__row__board-row__right\"\n",
    "i = 1\n",
    "for theater in karo_theatres:\n",
    "    dates_dicti = {}\n",
    "    url_sessions = url_theaters + \"?id=\" + karo_theatres[theater]['data-id']\n",
    "    r = requests.get(url_sessions)\n",
    "    if r.status_code == 200:\n",
    "        soup3 = BeautifulSoup(r.text, \"html.parser\")\n",
    "        d = soup3.findAll('select', class_='widget-select')[0]\n",
    "        dates = [i['data-id'] for i in d.findAll('option')]\n",
    "        for date in dates: \n",
    "            url_sessions_date = url_sessions + \"&date=\" + date\n",
    "            r2 = requests.get(url_sessions_date)\n",
    "            dates_dicti[date] = {}\n",
    "            if r2.status_code == 200:\n",
    "                films_on_date = BeautifulSoup(r2.text,'html.parser')\n",
    "                films_list = films_on_date.findAll('div',class_ = 'cinema-page-item__schedule__row')\n",
    "                for film in films_list:\n",
    "                    title = film.findAll('h3')[0].text\n",
    "                    ogran = [\", 0+\", \", 6+\", \", 12+\", \", 16+\", \", 18+\"]\n",
    "                    for org in ogran:\n",
    "                        if org in title:\n",
    "                            title = title.split(org)[0].strip()\n",
    "                    dates_dicti[date][title] = {}\n",
    "                    for types in film.findAll('div', class_ = 'cinema-page-item__schedule__row__board-row'):\n",
    "                        vision = types.findAll('div',class_ = left)[0].text.strip()\n",
    "                        time = [t.text for t in types.findAll('div',class_ = right)[0].findAll('a')]\n",
    "                        dates_dicti[date][title][vision] = time\n",
    "            else:\n",
    "                print('Нет даты с url=', url_sessions_date)  \n",
    "        \n",
    "    else:\n",
    "        print('Нет кинотеатра с url=', url_sessions)\n",
    "    for date, item in dates_dicti.items():\n",
    "        for name, sess in item.items():\n",
    "            cinema_id = get_id(name, \"cinemas\")\n",
    "            hall_id = get_id(theater, \"cinema_halls\")\n",
    "            for form, time in sess.items():\n",
    "                t = \", \".join(time)\n",
    "                cursor.execute(f\"insert into sessions values ('{i}', '{cinema_id}', '{hall_id}', '{date}', '{form}', '{t}', '{0}')\")\n",
    "                i += 1\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mori cinema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"insert into brand values (2, 'Mori cinema')\")\n",
    "    conn.commit()\n",
    "except sqlite3.IntegrityError:\n",
    "    print('Mori уже добавлен!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кинозалы Mori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_theaters_Mori(theatres):\n",
    "    dicti = {}\n",
    "    for theater in theatres:\n",
    "        dicti[theater.findAll('h2')[0].text.strip()] = {\n",
    "            'metro': None, \n",
    "            'address': theater.findAll('p')[0].text.strip(),\n",
    "            'phone': None,\n",
    "            'data-id': theater.findAll('a', class_=\"btn_cinema\", href=True)[0][\"href\"]\n",
    "        }\n",
    "    return dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mori-cinema.ru\"\n",
    "url_theaters = url + \"/cinema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url_theaters)\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    theatres = soup.findAll('ul', class_ =\"list_cinema\")[0].findAll('li')\n",
    "    mori_theatres = find_all_theaters_Mori(theatres)\n",
    "else:\n",
    "    print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_id_cin = cursor.execute('select id from cinema_halls').fetchall()\n",
    "n = len(last_id_cin)\n",
    "for i, theater in enumerate(mori_theatres):\n",
    "    adress = mori_theatres[theater]['address']\n",
    "    metro = mori_theatres[theater]['metro']\n",
    "    phone = mori_theatres[theater]['phone']\n",
    "    site_id = mori_theatres[theater]['data-id']\n",
    "    cursor.execute(f\"insert into cinema_halls values ('{n + 1}', {2}, '{site_id}', '{theater}', '{adress}', '{metro}', '{phone}')\")\n",
    "    n += 1\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильмы в Mori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_Mori(cinema_href):\n",
    "    url_cinema = url + cinema_href\n",
    "    r = requests.get(url_cinema)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    film_age = soup.findAll('div', class_='films_data')[0].findAll('p')[0].text.strip().split()[-1]\n",
    "    return film_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_cinemas_Mori(cinemas):\n",
    "    cinemas_dicti = {}\n",
    "    for cinema in cinemas: \n",
    "        try:\n",
    "            cinema_title = cinema.findAll('span', class_='title')[0].text.strip()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        else:    \n",
    "            try:\n",
    "                cinema_info = cinema.findAll('span',class_='name')[0].text.strip().split()\n",
    "                cinema_genres = \", \".join(cinema_info[:len(cinema_info) - 2])\n",
    "                cinema_duration = cinema_info[len(cinema_info) - 2]\n",
    "            except IndexError:\n",
    "                cinema_genres='undefined' \n",
    "                cinema_duration = 'undefined' \n",
    "            cinema_hallss = []\n",
    "            cinema_href = cinema.findAll('a', href=True)[0]['href']\n",
    "            cinema_age = age_Mori(cinema_href)\n",
    "            cinema_language='undefined'\n",
    "            cinemas_dicti[cinema_title] = {'age': cinema_age, 'duration': cinema_duration, 'language': cinema_language, 'genres': cinema_genres, 'halls': cinema_hallss,'href': cinema_href}\n",
    "    return cinemas_dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_films = url +\"/films\"\n",
    "r = requests.get(url_films)\n",
    "if r.status_code == 200:\n",
    "    soup2 = BeautifulSoup(r.text, \"html.parser\")\n",
    "    cinemas = soup2.findAll('div', class_='films')\n",
    "    mori_cinemas = find_all_cinemas_Mori(cinemas)\n",
    "else:\n",
    "    print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_id_cin = cursor.execute('select id from cinemas').fetchall()\n",
    "n = len(last_id_cin)\n",
    "for i, cinema in enumerate(mori_cinemas):\n",
    "    duration = mori_cinemas[cinema]['duration']\n",
    "    language = mori_cinemas[cinema]['language']\n",
    "    genres = mori_cinemas[cinema]['genres']\n",
    "    href = mori_cinemas[cinema]['href']\n",
    "    t = cursor.execute('select name from cinemas').fetchall()\n",
    "    flag = False\n",
    "    for j in t:\n",
    "        if cinema in j:\n",
    "            flag = True\n",
    "    if not flag:\n",
    "        cursor.execute(f\"insert into cinemas values ('{n + 1}', '{href}', '{cinema}', '{duration}', '{language}', '{genres}')\")\n",
    "        n += 1\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_with_zero(n):\n",
    "    if n < 10:\n",
    "        return \"0\"+str(n)\n",
    "    else:\n",
    "        return str(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_my(line_data):\n",
    "    mon_di = {\"янв.\":\"1\", \"фев.\":\"2\", \"мар.\":\"3\", \"апр.\":\"4\", \"май\":\"5\", \"июн.\":\"6\",\n",
    "                 \"июл.\":\"7\", \"авг.\":\"8\", \"сен.\":\"9\", \"окт.\":\"10\", \"ноя.\":\"11\", \"дек.\":\"12\"}\n",
    "    year = \"2020\"\n",
    "    if line_data[1].strip() == \"дек.\":\n",
    "        year = \"2019\"\n",
    "    d = year+\"-\"+str_with_zero(int(mon_di[line_data[1].strip()]))+\"-\"+ str_with_zero(int(line_data[0].strip()))\n",
    "    return d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back(date):\n",
    "    day = int(date[8:10])\n",
    "    month = int(date[5:7])\n",
    "    year = int(date[:4])\n",
    "    fir = day - 2\n",
    "    sec= day - 1\n",
    "    months_30 = (7, 5, 11, 10)\n",
    "    if fir > 0:\n",
    "        return date[:8] + str(fir), date[:8] + str(sec)\n",
    "    elif  fir == 0:\n",
    "        if month in months_30:\n",
    "            da = \"-30\"\n",
    "        elif month == 3:\n",
    "            if year % 4 == 0:\n",
    "                da = \"-29\" \n",
    "            else:\n",
    "                da = \"-28\"\n",
    "        elif month == 1:\n",
    "            return str(year - 1) +\"-\" +str_with_zero(12)+ \"31\", date[:8] + str_with_zero(sec)\n",
    "        else:\n",
    "            da = \"-31\"\n",
    "        return str(year) +\"-\" +str_with_zero(month - 1)+ da, date[:8] + str_with_zero(sec)\n",
    "    else:\n",
    "        if month in months_30:\n",
    "            da = \"-29\"\n",
    "            db = \"-30\"\n",
    "        elif month == 3:\n",
    "            if year % 4 == 0:\n",
    "                da = \"-28\" \n",
    "                db = \"-29\"\n",
    "            else:\n",
    "                da = \"-27\"\n",
    "                db = \"-28\"\n",
    "        elif month == 1:\n",
    "            return str(year - 1) +\"-\" +str_with_zero(12)+ \"-30\", str(year - 1) +\"-\" +str_with_zero(12)+ \"-31\"\n",
    "        else:\n",
    "            da = \"-30\"\n",
    "            db = \"-31\"\n",
    "        return str(year) +\"-\" +str_with_zero(month - 1)+ da, str(year) +\"-\" +str_with_zero(month - 1)+ db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = len(cursor.execute('select id from sessions').fetchall()) + 1\n",
    "for k, v in mori_theatres.items():\n",
    "    url_sessions = url + v['data-id'] + \"schedule.php\"\n",
    "    r = requests.get(url_sessions)\n",
    "    if r.status_code == 200:\n",
    "        f, s = \"\", \"\"\n",
    "        dic_dates = dict()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        first = soup.find('li', class_='notactivebtn')\n",
    "        second = soup.find('li', class_='activebtn') \n",
    "        if first and second:\n",
    "            f = dates_my(first.text.strip().split())\n",
    "            s = dates_my(second.text.strip().split())\n",
    "            if f < s:\n",
    "                today, tomorrow = back(f)\n",
    "            else:\n",
    "                today, tomorrow = back(s)\n",
    "        dates = soup.findAll('li', class_='activebtn')\n",
    "        dic_dates[\"1\"] = dict()\n",
    "        dic_dates[\"2\"] = dict()\n",
    "        dic_dates[\"1\"][\"data_num\"] = today\n",
    "        dic_dates[\"2\"][\"data_num\"] = tomorrow\n",
    "        for i in dates:\n",
    "            dic_dates[i[\"data-date\"]] = dict()\n",
    "            dic_dates[i[\"data-date\"]][\"data_num\"] = dates_my(i.text.strip().split())\n",
    "        tables = soup.findAll('table', class_='tbl_timetable')\n",
    "        for table_my in tables:\n",
    "            try:\n",
    "                da_now = table_my[\"data-table\"]\n",
    "            except KeyError:\n",
    "                if table_my[\"data-day\"] == \"today\":\n",
    "                    da_now = \"1\"\n",
    "                else:\n",
    "                    da_now = \"2\" \n",
    "            if da_now in dic_dates.keys():\n",
    "                sess_trs = table_my.findAll('tr')\n",
    "                notchange = False\n",
    "                dic_dates[da_now][\"film\"] = list() \n",
    "                for trs_my in sess_trs:\n",
    "                    kvdmf = trs_my.findAll(\"th\")\n",
    "                    if (len(kvdmf) == 0) and (trs_my[\"class\"] == [] or trs_my[\"class\"][0] != \"first\"):\n",
    "                        if trs_my.text.strip().split() == []:\n",
    "                            notchange = False\n",
    "                            #print(dic_film)\n",
    "                            dic_dates[da_now][\"film\"].append(dic_film)\n",
    "                            continue      \n",
    "                        if notchange == False:\n",
    "                            film_t = trs_my.find(\"td\")\n",
    "                            #print(da_now, film_t)\n",
    "                            if film_t:\n",
    "                                try:\n",
    "                                    title = film_t.find(\"a\").text.strip()\n",
    "                                except:\n",
    "                                    title = \"No title\"\n",
    "                                dic_film = dict()\n",
    "                                dic_film[\"title\"] = title\n",
    "                            notchange = True\n",
    "                        film_all = trs_my.findAll(\"td\")\n",
    "                        for i, td in enumerate(film_all):\n",
    "                            if len(film_all) == 3:\n",
    "                                if i == 1:\n",
    "                                    forma = td.text.strip()\n",
    "                                    dic_film[\"format\"] = dict()\n",
    "                                if i == 2:\n",
    "                                    time = td.findAll(\"a\", class_=\"aActualShedule\")\n",
    "                                    dic_film[\"format\"][forma] = [j.text.strip()[:5] for j in time]\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    forma = td.text.strip()\n",
    "                                if i == 1:\n",
    "                                    time = td.findAll(\"a\", class_=\"aActualShedule\")\n",
    "                                    dic_film[\"format\"][forma] = [j.text.strip()[:5] for j in time]\n",
    "        #print(dic_dates) \n",
    "        for jj, item in dic_dates.items():\n",
    "            for fil in item['film']:\n",
    "                cinema_id = get_id(fil['title'], \"cinemas\")\n",
    "                hall_id = get_id(k, \"cinema_halls\")\n",
    "                for form, time in fil['format'].items():\n",
    "                    t = \", \".join(time)\n",
    "                    tabl = cursor.execute('select cinema_id, hall_id, date, form, time, price from sessions').fetchall()\n",
    "                    flag = False\n",
    "                    for j in tabl:\n",
    "                        if ({cinema_id}, {hall_id}, {item['data_num']}, {form}, {t}, {0}) in j:\n",
    "                            flag = True\n",
    "                    if not flag:\n",
    "                        if str(cinema_id).isdigit(): \n",
    "                            cursor.execute(f\"insert into sessions values ('{iii}', '{cinema_id}', '{hall_id}', '{item['data_num']}', '{form}', '{t}', '{0}')\")\n",
    "                            iii += 1\n",
    "                            conn.commit()                    \n",
    "    else:\n",
    "        print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Викисинема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"insert into brand values (3, 'WikiCinema')\")\n",
    "    conn.commit()\n",
    "except sqlite3.IntegrityError:\n",
    "    print('Wiki уже добавлен!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_theaters_viki(theatres):\n",
    "    dicti = {}\n",
    "    for theater in theatres:\n",
    "        name = theater.find('div', class_=\"cinema-item-trc\").text.strip()\n",
    "        city = theater.find('div', class_=\"cinema-item-city\").text.strip()\n",
    "        href = theater.findAll('a')[0][\"href\"]\n",
    "        dicti[name + \"(\"+city+\")\"] = {'data-id': href}\n",
    "        url_theater = dicti[name + \"(\"+city+\")\"]['data-id'] + \"kontakty/\"\n",
    "        r = requests.get(url_theater)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            dicti[name + \"(\"+city+\")\"] = {\n",
    "            'metro': None, \n",
    "            'address': soup.find('div', class_ =\"adress\").text.strip(),\n",
    "            'phone': \"\".join(soup.find('div', class_ =\"phone\").text.strip().split()),\n",
    "            'data-id': href\n",
    "            }\n",
    "        else:\n",
    "            print(\"Страница не найдена\")\n",
    "    return dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Малибу(Липецк)': {'metro': None, 'address': 'Киноплекс «Малибу», г. Липецк, ул. Терешковой, д. 35 б', 'phone': '(4742)51-76-38', 'data-id': 'http://malibu.wikicinema.ru/'}, 'Парк Плаза(Электросталь)': {'metro': None, 'address': 'ул. Корешкова, 3, Электросталь, Московская обл.', 'phone': '', 'data-id': 'http://plaza.wikicinema.ru/'}, 'Выходной(Люберцы)': {'metro': None, 'address': 'г. Люберцы, Московская область, Октябрьский проспект, 112', 'phone': '+7(499)500-49-25', 'data-id': 'http://lubercy.wikicinema.ru/'}, 'ЗигЗаг(Москва)': {'metro': None, 'address': 'г. Москва, ул. Лобненская, д. 4а, ТРЦ «Зиг-Заг»', 'phone': '+7499290-37-09', 'data-id': 'http://zigzag.wikicinema.ru/'}}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://wikicinema.ru/\"\n",
    "r = requests.get(url)\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    theatres = soup.findAll('div', class_ =\"cinema-item\")\n",
    "    viki_theatres = find_all_theaters_viki(theatres)\n",
    "else:\n",
    "    print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_id_cin = cursor.execute('select id from cinema_halls').fetchall()\n",
    "n = len(last_id_cin)\n",
    "for i, theater in viki_theatres.items():\n",
    "    adress = theater['address']\n",
    "    metro = theater['metro']\n",
    "    phone = theater['phone']\n",
    "    site_id = theater['data-id']\n",
    "    cursor.execute(f\"insert into cinema_halls values ('{n + 1}', {3}, '{site_id}', '{i}', '{adress}', '{metro}', '{phone}')\")\n",
    "    n += 1\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2019-12-22': [{'Полицейский с Рублевки. Новогодний беспредел 2': {'genre': 'комедия', 'age': '12+', 'format': {'2D': ['09:10', '11:05', '13:40', '15:30', '17:20', '18:05', '19:10', '20:00', '21:00', '21:55', '22:50', '23:50']}}, 'Звёздные Войны: Скайуокер. Восход': {'genre': 'фантастика, экшн', 'age': '16+', 'format': {'2D': ['09:00', '10:50', '11:30', '14:10', '16:50', '17:40', '19:30', '21:05', '22:00'], '3D': ['15:25']}}, 'Джуманджи: Новый уровень': {'genre': 'фэнтези, боевик, комедия, приключения', 'age': '12+', 'format': {'2D': ['09:10', '11:30', '15:20', '17:20', '19:40'], '3D-Atmos': ['13:00']}}, 'Холодное сердце 2': {'genre': 'анимация, приключения, семейный', 'age': '6+', 'format': {'2D': ['11:05', '13:05', '15:05', '17:05', '19:05']}}, 'Чёрное рождество': {'genre': 'ужасы, триллер, детектив', 'age': '18+', 'format': {'2D': ['09:00', '13:30', '20:20', '22:20']}}, 'Фиксики против кработов': {'genre': 'анимация, приключения, комедия, музыкальный, семейный', 'age': '6+', 'format': {'2D': ['09:20', '13:50', '15:35']}}, 'Исцеляющая': {'genre': 'фэнтези', 'age': '16+', 'format': {'2D': ['22:10', '23:55']}}, 'Сиротский Бруклин': {'genre': 'драма, криминал', 'age': '18+', 'format': {'2D': ['08:50']}}, 'Рождество на двоих': {'genre': 'мелодрама, комедия', 'age': '16+', 'format': {'2D': ['11:40']}}, 'Курьер': {'genre': 'боевик, драма, триллер', 'age': '18+', 'format': {'2D': ['23:45']}}}], '2019-12-23': [], '2019-12-24': [], '2019-12-25': [], '2019-12-26': [], '2019-12-27': [], '2019-12-28': [], '2019-12-29': [], '2019-12-30': [], '2019-12-31': [], '2020-01-01': []}\n",
      "{'2019-12-22': [{'Полицейский с Рублевки. Новогодний беспредел 2': {'genre': 'комедия', 'age': '12+', 'format': {'2D': ['09:05', '13:20', '18:00', '20:00', '21:55', '23:50', '19:20']}}, 'Звёздные Войны: Скайуокер. Восход': {'genre': 'фантастика, экшн', 'age': '16+', 'format': {'3D': ['15:20'], '2D': ['23:35', '09:00', '11:40', '18:25', '21:05']}}, 'Джуманджи: Новый уровень': {'genre': 'фэнтези, боевик, комедия, приключения', 'age': '12+', 'format': {'3D': ['11:00'], '2D': ['09:15', '21:15', '16:05']}}, 'Холодное сердце II': {'genre': 'анимация, приключения, семейный', 'age': '6+', 'format': {'2D': ['13:20', '15:20', '17:20']}}, 'Фиксики против кработов': {'genre': 'анимация, приключения, комедия, музыкальный, семейный', 'age': '6+', 'format': {'2D': ['11:40', '14:20']}}, 'Рождество на двоих': {'genre': 'мелодрама, комедия', 'age': '16+', 'format': {'2D': ['23:45']}}}], '2019-12-23': [], '2019-12-24': [], '2019-12-25': []}\n",
      "{'2019-12-22': [{}], '2019-12-23': [], '2019-12-24': [], '2019-12-25': [], '2019-12-26': [], '2019-12-27': [], '2019-12-28': [], '2019-12-29': [], '2019-12-30': [], '2019-12-31': [], '2020-01-01': []}\n",
      "{'2019-12-22': [{}], '2019-12-23': [], '2019-12-24': [], '2019-12-25': [], '2019-12-26': [], '2019-12-27': [], '2019-12-28': []}\n"
     ]
    }
   ],
   "source": [
    "jjj = len(cursor.execute('select id from sessions').fetchall()) + 1\n",
    "for k, v in viki_theatres.items():\n",
    "    url_sess = v['data-id'] \n",
    "    r = requests.get(url_sess)\n",
    "    if r.status_code == 200:\n",
    "        dic_dates = dict()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        days = soup.findAll('a', class_ =\"afisha-day\")\n",
    "        for day in days:\n",
    "            if not(\"disabled\" in day[\"class\"]):\n",
    "                date = day[\"data-date\"][6:]+\"-\"+day[\"data-date\"][3:5]+\"-\"+day[\"data-date\"][:2]\n",
    "                dic_dates[date] = list()      \n",
    "        d_sessions = soup.findAll('div', class_ =\"afisha-seance-wrapper\")\n",
    "        for d_session in d_sessions:\n",
    "            date = d_session[\"data-date\"][6:]+\"-\"+d_session[\"data-date\"][3:5]+\"-\"+d_session[\"data-date\"][:2]\n",
    "            films = d_session.findAll('div', class_ =\"afisha-list-item\")\n",
    "            films_dic = dict()\n",
    "            for film in films:\n",
    "                films_dic[film.find(\"h3\").text] = dict()\n",
    "                films_dic[film.find(\"h3\").text][\"genre\"] = film.find(\"p\", class_=\"film-genre\").text.rsplit(\" \",1)[0]\n",
    "                films_dic[film.find(\"h3\").text][\"age\"] = film.find(\"p\", class_=\"film-genre\").text.rsplit(\" \",1)[1]\n",
    "                films_dic[film.find(\"h3\").text][\"format\"] = dict()\n",
    "                for ii in film.findAll(\"div\", class_=\"film-seances-item\"):\n",
    "                    form = ii.find(\"li\")[\"data-format\"]\n",
    "                    films_dic[film.find(\"h3\").text][\"format\"][form.strip()] = list()\n",
    "                for ii in film.findAll(\"div\", class_=\"film-seances-item\"):\n",
    "                    form = ii.find(\"li\")[\"data-format\"]\n",
    "                    films_dic[film.find(\"h3\").text][\"format\"][form.strip()].append(ii.find(\"a\", class_=\"seance\").text)\n",
    "            dic_dates[date].append(films_dic) \n",
    "            for jj, item in dic_dates.items():\n",
    "                for film in item:\n",
    "                    for name, info in film.items():\n",
    "                        cinema_id = get_id(name, \"cinemas\")\n",
    "                        hall_id = get_id(k, \"cinema_halls\")\n",
    "                        for form, time in info['format'].items():\n",
    "                            t = \", \".join(time)\n",
    "                            tabl = cursor.execute('select cinema_id, hall_id, date, form, time, price from sessions').fetchall()\n",
    "                            flag = False\n",
    "                            for j in tabl:\n",
    "                                if ({cinema_id}, {hall_id}, {jjj}, {form}, {t}, {0}) in j:\n",
    "                                    flag = True\n",
    "                            if not flag:\n",
    "                                if str(cinema_id).isdigit(): \n",
    "                                    cursor.execute(f\"insert into sessions values ('{jjj}', '{cinema_id}', '{hall_id}', '{jj}', '{form}', '{t}', '{0}')\")\n",
    "                                    jjj += 1\n",
    "                                    conn.commit()    \n",
    "    else:\n",
    "        print(\"Страница не найдена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
